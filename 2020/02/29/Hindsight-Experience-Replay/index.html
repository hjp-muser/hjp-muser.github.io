<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="1. HER 概念对于机器人的强化学习算法，存在的挑战就是奖励函数的设置，不但需要考虑如何反映任务的完成水平，同时还需要指导策略的优化。有时，奖励函数的设置还需涉及到具体领域的专业知识。如果不对这些复杂的工程问题进行考虑，而简单用奖励函数表示任务成功或失败，就会造成奖励系数问题。就算仔细设计了奖励函数，可扩展性和鲁棒性也不高。 为了解决奖励稀疏的问题，本文提出了 HER 算法。HER 算法可以针对">
<meta name="keywords" content="强化学习,HER">
<meta property="og:type" content="article">
<meta property="og:title" content="Hindsight Experience Replay">
<meta property="og:url" content="http://yoursite.com/2020/02/29/Hindsight-Experience-Replay/index.html">
<meta property="og:site_name" content="Huangjp Blog">
<meta property="og:description" content="1. HER 概念对于机器人的强化学习算法，存在的挑战就是奖励函数的设置，不但需要考虑如何反映任务的完成水平，同时还需要指导策略的优化。有时，奖励函数的设置还需涉及到具体领域的专业知识。如果不对这些复杂的工程问题进行考虑，而简单用奖励函数表示任务成功或失败，就会造成奖励系数问题。就算仔细设计了奖励函数，可扩展性和鲁棒性也不高。 为了解决奖励稀疏的问题，本文提出了 HER 算法。HER 算法可以针对">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2020/02/29/Hindsight-Experience-Replay/HER.png">
<meta property="og:updated_time" content="2020-03-04T04:51:37.453Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hindsight Experience Replay">
<meta name="twitter:description" content="1. HER 概念对于机器人的强化学习算法，存在的挑战就是奖励函数的设置，不但需要考虑如何反映任务的完成水平，同时还需要指导策略的优化。有时，奖励函数的设置还需涉及到具体领域的专业知识。如果不对这些复杂的工程问题进行考虑，而简单用奖励函数表示任务成功或失败，就会造成奖励系数问题。就算仔细设计了奖励函数，可扩展性和鲁棒性也不高。 为了解决奖励稀疏的问题，本文提出了 HER 算法。HER 算法可以针对">
<meta name="twitter:image" content="http://yoursite.com/2020/02/29/Hindsight-Experience-Replay/HER.png">
  <link rel="canonical" href="http://yoursite.com/2020/02/29/Hindsight-Experience-Replay/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Hindsight Experience Replay | Huangjp Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Huangjp Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/29/Hindsight-Experience-Replay/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Huangjp">
      <meta itemprop="description" content="学而不思则罔 思而不学则殆">
      <meta itemprop="image" content="/images/dog.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Huangjp Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Hindsight Experience Replay

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-02-29 17:57:04" itemprop="dateCreated datePublished" datetime="2020-02-29T17:57:04+08:00">2020-02-29</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-04 12:51:37" itemprop="dateModified" datetime="2020-03-04T12:51:37+08:00">2020-03-04</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/强化学习/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a></span>

                
                
              
            </span>
          

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/02/29/Hindsight-Experience-Replay/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/02/29/Hindsight-Experience-Replay/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="1-HER-概念"><a href="#1-HER-概念" class="headerlink" title="1. HER 概念"></a>1. HER 概念</h2><p>对于机器人的强化学习算法，存在的挑战就是奖励函数的设置，不但需要考虑如何反映任务的完成水平，同时还需要指导策略的优化。有时，奖励函数的设置还需涉及到具体领域的专业知识。如果不对这些复杂的工程问题进行考虑，而简单用奖励函数表示任务成功或失败，就会造成奖励系数问题。就算仔细设计了奖励函数，可扩展性和鲁棒性也不高。</p>
<p>为了解决奖励稀疏的问题，本文提出了 HER 算法。HER 算法可以针对稀疏和二进制奖励的情况，提高样本效率，进而避免涉及复杂的奖励函数。可以将 HER 算法与其他 off-policy 强化学习算法结合。二进制奖励是指奖励只有两种值，出现在任务成功或任务失败的时候。</p>
<a id="more"></a>
<p>HER 算法具备推理能力，能够实现系统中任意状态为目标的任务。HER 参考论文 <a href="#ref1">[1]</a>  的通用策略设计，对于输入，不仅输入当前状态，而且需要目标状态。</p>
<p>HER 背后的核心思想是，在每个 episode 中都回放不同的目标（即当前 episode 需要实现的目标），而不止是最终要实现的目标。</p>
<h2 id="2-相关知识"><a href="#2-相关知识" class="headerlink" title="2. 相关知识"></a>2. 相关知识</h2><h3 id="2-1-RL-基础"><a href="#2-1-RL-基础" class="headerlink" title="2.1 RL 基础"></a>2.1 RL 基础</h3><p>最优动作值函数（对于最优策略 $\pi^<em>$，满足 $Q^{\pi^</em>}(s,a) \ge Q^\pi(s,a)$，$\forall s \in S, \forall a \in A$）：</p>
<script type="math/tex; mode=display">
Q^{*} (s,a) = \mathbb{E}_{s'\sim p(\cdot|s,a)} \left[ r(s,a) + \gamma \mathop{\max}_{a'\in A} Q^*(s',a') \right]
\tag{1}</script><h3 id="2-2-DQN"><a href="#2-2-DQN" class="headerlink" title="2.2 DQN"></a>2.2 DQN</h3><p>DQN 存在两种策略：行为策略和目标策略。行为策略执行的是 $\epsilon$-greedy 策略，目标策略执行的是 greedy 策略。</p>
<p>每次训练，使用行为策略产生轨迹 $(s_t,a_t,r_t,s_{t+1})$，并存储到回放池中。训练的目标函数是：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathbb{E}(Q(s_t,a_t) - y_t)^2 \\
y_t = r_t + \gamma \max_{a'\in A} Q(s_{t+1}, a')
\tag{2}</script><p>其中 $Q(s,a)$ 表示动作值函数的函数逼近。样本从回放池中采样。</p>
<h3 id="2-3-DDPG"><a href="#2-3-DDPG" class="headerlink" title="2.3 DDPG"></a>2.3 DDPG</h3><p>DDPG 是一种采用 AC 框架的算法。A 表示策略网络：$\pi: S \rightarrow A$，C 表示动作值网络：$Q: S \times A \rightarrow \mathbb{R}$ 。</p>
<p>同样也采用行为策略在每个 episode 中产生轨迹。行为策略的表达式为 $\pi_b(s) = \pi(s) + \mathcal{N}(0,1)$ ，表示一个确定策略，，加上一个随机分布（分布类型可以自定义）。critic 的目标与 DQN 的训练目标相似，只不过目标策略不是 greedy 策略，而是确定策略 $\pi(s)$ 。critic 的目标为：$y_t = r_t + \gamma Q(s_{t+1},\pi(s_{t+1}))$ 。actor 的目标函数为 $\mathcal{L}_a = -\mathbb{E}_s Q(s,\pi(s))$ 。样本同样从回放池中采样。</p>
<h3 id="2-4-UVFA"><a href="#2-4-UVFA" class="headerlink" title="2.4 UVFA"></a>2.4 UVFA</h3><p>全称为 Universal Value Function Approximators，出自论文 <a href="#ref1">[1]</a> 。UVFA 是 DQN 的一个扩展，设立了不止一个目标去优化。假设其中一个目标 $g \in \mathcal{G}$，对应的奖励函数写为：$r_g: S \times A \rightarrow \mathbb{R}$ 。</p>
<p>每个 episode 开始时，都根据某种分布采样一个 state-goal 分布，记为 $p(s_0,g)$ 。这个目标 $g$ 将在这个 episode 中保持不变。接下来每个时间步长，智能体的输入不仅是状态 $s_t$，同时还有目标 $g$，因此策略的形式可以表示为：$\pi: S \times \mathcal{G} \rightarrow A$，奖励函数的形式为 $r_t = r_g(s_t,a_t)$ 。</p>
<p>动作值函数同样也不止依赖于状态动作对，也依赖于目标 $g$ ，表示为 $Q^\pi(s_t,a_t,g) = \mathbb{E}[R_t|s_t,a_t,g]$ 。</p>
<h2 id="3-具体算法"><a href="#3-具体算法" class="headerlink" title="3. 具体算法"></a>3. 具体算法</h2><p>定义一个谓语：$f_g:S \rightarrow \{0,1\}$ 。目标表示为能够实现满足 $f_g(s) = 1$  的任意状态。</p>
<p>例如，如果指定状态空间的某一状态为目标，则 $f_g(s) = [s=g]$ 。如果指定状态空间某一维度的值为目标（假设 $S=\mathbb{R}^2$），则 $f_g((x,y)) = [x = g]$ 。</p>
<p>另外假设，对于状态空间的任意状态，我们都能找到一个目标，使得该状态满足要求。用数学符号定义为：存在一个映射 ：$m: S \rightarrow \mathcal{G} \;\; s.t. \;\; \forall_{s \in S} f_{m(s)}(s)=1$ 。最简单的，如果该映射是个很恒等映射，即 $\mathcal{G} = S$，$f_g(s) = [s=g]$， 显然该假设成立。 再举一个例子，如果状态空间是二维的，目标空间是一维的，则该假设也能够成立，例如其中一种情况为 $m((x,y))=x$ 。</p>
<p>HER 背后的思想是，在经历过一些 episode 之后，即经验回放池中存储着一系列经验和每个 episode 的目标（目标空间的一个子集）。HER 需要决定的是每次回放哪些目标的轨迹。文中称之为回放策略 $\mathbb{S}$。</p>
<p>HER 可视为一种循序渐进的教学，先从简单的容易实现的目标回放，再到困难的最终的目标回放。</p>
<p>算法伪代码如下图所示：</p>
<p><img src="/2020/02/29/Hindsight-Experience-Replay/HER.png" alt="HER" style="zoom: 67%;"></p>
<p>伪代码中最重要的就是采样策略 $\mathbb{S}$ 。</p>
<h2 id="4-工程设置"><a href="#4-工程设置" class="headerlink" title="4. 工程设置"></a>4. 工程设置</h2><p>环境：7 个自由度的机械臂</p>
<p>任务设定：(1) 用机械臂将物体推向目标处。(2) 用机械臂给滑块施力，让它滑到目标处。(3) 用机械臂夹起物体并放置到空间某处。</p>
<p>状态空间：机械臂的关节角度和速度（包含线性速度、角速度），关节位置，物体的转动和速度。</p>
<p>目标：目标设定为靠近某个状态下物体的位置，表示为 $f_g(s)=[|g-s_{object}| \le \epsilon]$ ，其中 $s_{object}$ 表示状态 $s$ 下物体的位置。</p>
<p>奖励：$r(a,s,g) = -[f_g(s’)=0]$，其中 $s’$ 表示在 状态 $s$ 下执行动作 $a$ 后的下一个状态。这表示如果 $s’$ 不满足目标 $g$ 的要求，则奖励设置为 -1，否则设置为 1 。</p>
<p>动作：四维输出，前面三维是抓手的绝对位置，最后一维是抓手的两支手指的距离。注意机械臂的控制是通过运动学进行的，根据抓手期待的位置去控制。</p>
<p>目标回放策略 $\mathbb{S}$：文中总共设计了四种策略。</p>
<ul>
<li>final：每个 episode 的最后一个状态作为目标。</li>
<li>future：从当前的 episode 中收集可能在未来遇见的状态作为目标。</li>
<li>episode：从当前的 episode 中随机采样状态作为目标。</li>
<li>random：从所有遇见的状态中随机采样状态作为目标。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><span id="ref1">[1]</span> Schaul, T., Horgan, D., Gregor, K., &amp; Silver, D. (2015). Universal value function approximators. <em>32nd International Conference on Machine Learning, ICML 2015</em>, <em>2</em>, 1312–1320. International Machine Learning Society (IMLS).</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/强化学习/" rel="tag"># 强化学习</a>
            
              <a href="/tags/HER/" rel="tag"># HER</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/02/25/Reinforcement-learning-with-unsupervised-auxiliary-tasks/" rel="next" title="Reinforcement learning with unsupervised auxiliary tasks">
                  <i class="fa fa-chevron-left"></i> Reinforcement learning with unsupervised auxiliary tasks
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/03/04/Generative-Adversarial-Imitation-Learning/" rel="prev" title="Generative Adversarial Imitation Learning">
                  Generative Adversarial Imitation Learning <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-HER-概念"><span class="nav-text">1. HER 概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-相关知识"><span class="nav-text">2. 相关知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-RL-基础"><span class="nav-text">2.1 RL 基础</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-DQN"><span class="nav-text">2.2 DQN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-DDPG"><span class="nav-text">2.3 DDPG</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-UVFA"><span class="nav-text">2.4 UVFA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-具体算法"><span class="nav-text">3. 具体算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-工程设置"><span class="nav-text">4. 工程设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-text">参考文献</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/dog.jpg"
      alt="Huangjp">
  <p class="site-author-name" itemprop="name">Huangjp</p>
  <div class="site-description" itemprop="description">学而不思则罔 思而不学则殆</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span>
        
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span>
        
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Huangjp</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>

<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'BkRC1SYitLwztmNcM1fllQXg-gzGzoHsz',
    appKey: '84rnDPQXuQoaFph0FANDMMJL',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
